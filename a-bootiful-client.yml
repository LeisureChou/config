spring:
    datasource:
        name: test
        url: jdbc:oracle:thin:@10.180.224.165:9530:mot
        username: mot
        password: gtjamot
        # 使用druid数据源
        type: com.alibaba.druid.pool.DruidDataSource
        driver-class-name: oracle.jdbc.driver.OracleDriver
        filters: stat
        maxActive: 60
        initialSize: 1
        maxWait: 60000
        minIdle: 1
        timeBetweenEvictionRunsMillis: 60000
        minEvictableIdleTimeMillis: 300000
        validationQuery: select 'x' FROM DUAL
        testWhileIdle: true
        testOnBorrow: false
        testOnReturn: false
        poolPreparedStatements: true
        maxOpenPreparedStatements: 20
        defaultAutoCommit: true
mybatis:
  mapperLocations: classpath:mapper/*.xml
  typeAliasesPackage: com.gtja.kafka.domain

#个推服务器配置
getTuiConfig:
  API: 10.180.227.83
  PORT: 5266
  #企业版本
  #appId: nD7bn1E30u889ln4Ht6ny2
  #appKey: 0Td3DwgyvQ9qE37eKlW4y4
  #masterSecret: T7DEeKCwjn8eV9u5yxyLeA
     #测试环境
  #appKey: 3jj5X8mfA2AIwuC3zqbT87
  #appId: cNPBDzlHGw7XCPLBSAVb15
 # masterSecret:  2kDNz9boQc9sUKC5T47Hn1
  #正式环境
  appId: ABEjABqCDuAA1kjRkPWji1
  appKey: kyz1ExCSgEAbtyyjLn4AAA
  masterSecret: 3sJdE7AiseA6u1CZLQ9Gi9

  #To App 消费者配置
toAppConfig:
  zookeeper_connect: kafka01:2181,kafka02:2181,kafka03:2181
  group_id: app_consumer
  topic: toApp_dataP
  auto_commit_enable: true
  auto_commit_interval_ms: 60000
  rebalance_max_retries: 4
  auto_offset_reset: smallest
  client_num: 2
  blockingQueueSize: 100
  corePoolSize: 1
  maximumPoolSize: 2
  keepAliveTime: 36000
#To List 消费者配置
toListConfig:
  zookeeper_connect: kafka01:2181,kafka02:2181,kafka03:2181
  group_id: list_consumer
  topic: toList_dataP
  auto_commit_enable: true
  auto_commit_interval_ms: 60000
  rebalance_max_retries: 4
  auto_offset_reset: smallest
  client_num: 10
  blockingQueueSize: 100
  corePoolSize: 1
  maximumPoolSize: 2
  keepAliveTime: 36000

#To Single 消费者配置
toSingleConfig:
  zookeeper_connect:   kafka01:2181,kafka02:2181,kafka03:2181
  group_id: single_consumer
  topic: toSingle_dataP
  auto_commit_enable: true
  auto_commit_interval_ms: 60000
  rebalance_max_retries: 4
  auto_offset_reset: smallest
  client_num: 10
  blockingQueueSize: 100
  corePoolSize: 1
  maximumPoolSize: 2
  keepAliveTime: 36000
  #推送历史生产者

pushLogProducerConfig:
  bootstrapServers: kafka01:9092,kafka02:9092,kafka03:9092
  zookeeper_connect: kafka01:2181,kafka02:2181,kafka03:2181
  topic: push_logP
  acks: all
  retries: 0
  batchSize: 16384
  lingerMs: 1
  bufferMemory: 33554432
  keySerializer: org.apache.kafka.common.serialization.StringSerializer
  valueSerializer: org.apache.kafka.common.serialization.StringSerializer
  #推送历史消费者

pushLogConsumerConfig:
   zookeeper_connect: kafka01:2181,kafka02:2181,kafka03:2181
   group_id: push_log_consumer
   topic: push_logP
   auto_commit_enable: true
   auto_commit_interval_ms: 60000
   rebalance_max_retries: 4
   auto_offset_reset: smallest
   client_num: 2
   blockingQueueSize: 100
   corePoolSize: 1
   maximumPoolSize: 2
   keepAliveTime: 36000
